{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd4cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e06997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'C:\\Users\\D\\Desktop\\Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5502f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c46a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e696c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5ee9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bf12e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb92b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28d50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65627151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>316</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>307</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>324</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>319</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>326</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>328</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>300</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>293</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "428        316          103                  2  2.0   4.5  8.74         0\n",
       "490        307          105                  2  2.5   4.5  8.12         1\n",
       "53         324          112                  4  4.0   2.5  8.10         1\n",
       "336        319          110                  3  3.0   2.5  8.79         0\n",
       "154        326          108                  3  3.0   3.5  8.89         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "22         328          116                  5  5.0   5.0  9.50         1\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "493        300           95                  2  3.0   1.5  8.22         1\n",
       "15         314          105                  3  3.5   2.5  8.30         0\n",
       "168        293           97                  2  2.0   4.0  7.80         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dccb640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "s=MinMaxScaler()\n",
    "x_train=s.fit_transform(x_train)\n",
    "x_test=s.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6275180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4893617 , 0.37037037, 0.25      , ..., 0.875     , 0.62179487,\n",
       "        0.        ],\n",
       "       [0.29787234, 0.44444444, 0.25      , ..., 0.875     , 0.42307692,\n",
       "        1.        ],\n",
       "       [0.65957447, 0.7037037 , 0.75      , ..., 0.375     , 0.41666667,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.14893617, 0.07407407, 0.25      , ..., 0.125     , 0.45512821,\n",
       "        1.        ],\n",
       "       [0.44680851, 0.44444444, 0.5       , ..., 0.375     , 0.48076923,\n",
       "        0.        ],\n",
       "       [0.        , 0.14814815, 0.25      , ..., 0.75      , 0.32051282,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "35a74d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 18ms/step - loss: 0.6473 - val_loss: 0.6313\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6211 - val_loss: 0.6040\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5925 - val_loss: 0.5741\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5610 - val_loss: 0.5409\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5262 - val_loss: 0.5039\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4872 - val_loss: 0.4623\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4439 - val_loss: 0.4152\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3946 - val_loss: 0.3617\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3389 - val_loss: 0.3007\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2754 - val_loss: 0.2316\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2043 - val_loss: 0.1536\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1301 - val_loss: 0.0833\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0778 - val_loss: 0.0734\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0722 - val_loss: 0.0742\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0685 - val_loss: 0.0669\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0659 - val_loss: 0.0645\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0648 - val_loss: 0.0640\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0633 - val_loss: 0.0638\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0622 - val_loss: 0.0630\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0610 - val_loss: 0.0622\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0599 - val_loss: 0.0617\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0588 - val_loss: 0.0614\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0581 - val_loss: 0.0607\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0572 - val_loss: 0.0602\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0564 - val_loss: 0.0598\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0558 - val_loss: 0.0588\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0552 - val_loss: 0.0582\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0546 - val_loss: 0.0577\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.0574\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0533 - val_loss: 0.0566\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0528 - val_loss: 0.0561\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0522 - val_loss: 0.0555\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0517 - val_loss: 0.0547\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0511 - val_loss: 0.0545\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0506 - val_loss: 0.0539\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0500 - val_loss: 0.0528\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0497 - val_loss: 0.0529\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0490 - val_loss: 0.0518\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0488 - val_loss: 0.0515\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0485 - val_loss: 0.0512\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0481 - val_loss: 0.0507\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0478 - val_loss: 0.0504\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.0503\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0470 - val_loss: 0.0497\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0467 - val_loss: 0.0491\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0466 - val_loss: 0.0487\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0462 - val_loss: 0.0488\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0462 - val_loss: 0.0482\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0455 - val_loss: 0.0485\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0456 - val_loss: 0.0476\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0452 - val_loss: 0.0476\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0450 - val_loss: 0.0472\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.0469\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.0467\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.0465\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0445 - val_loss: 0.0464\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.0462\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.0462\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.0460\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.0461\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0441 - val_loss: 0.0462\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0436 - val_loss: 0.0458\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0436 - val_loss: 0.0457\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.0457\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0434 - val_loss: 0.0457\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0456\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0456\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0457\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0431 - val_loss: 0.0456\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0431 - val_loss: 0.0455\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.0455\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0431 - val_loss: 0.0458\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0429 - val_loss: 0.0456\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0429 - val_loss: 0.0454\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0432 - val_loss: 0.0456\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0427 - val_loss: 0.0454\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0456\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0456\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.0455\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0456\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0430 - val_loss: 0.0455\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0462\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.0455\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0454\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.0454\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.0452\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0453\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0456\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0452\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.0453\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.0450\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0424 - val_loss: 0.0453\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.0454\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.0451\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0420 - val_loss: 0.0453\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.0453\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0451\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0420 - val_loss: 0.0453\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0453\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0455\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0452\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0418 - val_loss: 0.0450\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0417 - val_loss: 0.0450\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0451\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.0450\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0449\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0451\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0452\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.0449\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0450\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0449\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0450\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0451\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0449\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0449\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0451\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0449\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0448\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0414 - val_loss: 0.0449\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0423 - val_loss: 0.0448\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0415 - val_loss: 0.0450\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0447\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0448\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0449\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0450\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0418 - val_loss: 0.0449\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0448\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0450\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0448\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0450\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.0449\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0416 - val_loss: 0.0448\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0449\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0449\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0448\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0448\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0448\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0448\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0448\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0447\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0447\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0448\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0450\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0447\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0448\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0449\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0448\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0448\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.0448\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0448\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0447\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0448\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.0448\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0451\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0447\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0410 - val_loss: 0.0448\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0410 - val_loss: 0.0451\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0447\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0446\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0447\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.0447\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.0446\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.0447\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0446\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0447\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0447\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0448\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0447\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0447\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0447\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.0447\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0448\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0447\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0447\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0446\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0447\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0406 - val_loss: 0.0448\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0446\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0446\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0448\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0447\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0402 - val_loss: 0.0446\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0403 - val_loss: 0.0446\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0449\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0446\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0447\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0404 - val_loss: 0.0446\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.0450\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0447\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.0446\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0406 - val_loss: 0.0447\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0447\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0446\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0447\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0404 - val_loss: 0.0446\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0445\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0414 - val_loss: 0.0445\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0446\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0445\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0449\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "m=tf.keras.Sequential([tf.keras.layers.Dense(7,activation=\"relu\"),tf.keras.layers.Dense(7,activation=\"relu\"),tf.keras.layers.Dense(1,activation=\"linear\")])\n",
    "m.compile(loss=tf.keras.losses.mae,optimizer=tf.keras.optimizers.Adam())\n",
    "history=m.fit(x_train,y_train,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e73d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=m.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a75ea8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7757637087314284"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59c7a8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6182c182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[86.72278]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict([[487,158,4,4.5,4.5,9.65,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235dfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
